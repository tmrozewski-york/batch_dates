{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e756d0c",
   "metadata": {},
   "source": [
    "# Batching editing publication dates in OJS using API\n",
    "\n",
    "This code will use the OJS 3.3 API to batch edit the publication date for published articles (\"publications\"). in the archive of an OJS journal. Here's the link to the API documentation: https://docs.pkp.sfu.ca/dev/api/ojs/3.3\n",
    "\n",
    "The journal's back issues were all uploaded at one time, long after print publication. The publication dates in OJS match the date of OJS upload, not of journal publication. This has implications for harvesting, citation output, DOI registration (and cost), and copyright.\n",
    "\n",
    "The current OJS API can only make get requests for issues, not put. That means I had to update all the issue publication dates through the web interface.\n",
    "\n",
    "## Workflow\n",
    "\n",
    "Schematically:\n",
    "1. GET list of all issues (filter 2016 and prior)\n",
    "2. In a loop:\n",
    "    1. Pull the issue IDs\n",
    "    2. use issue IDs to GET issue data\n",
    "    3. pull pub date\n",
    "    4. pull sub and pub IDs from attached articles\n",
    "    5. in a loop:\n",
    "        1. use sub and pub ID to PUT unpublish publication\n",
    "        2. PUT edit publication date\n",
    "        3. PUT edit publish publication\n",
    "\n",
    "## Managing credentials and endpoints\n",
    "\n",
    "We need a list of endpoints and the API token. Problems is, the endpoints will be generated dynamically by the submission and publication IDs so I'm not sure how that will work in the implementation.\n",
    "\n",
    "For now I'm using placeholders and I've got CSV of credentials looking like this (two rows: one header, one values):\n",
    "\n",
    "* `token`: `SUPER TOP SECRET API TOKEN`\n",
    "* `subs_endpoint`: `https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions`\n",
    "* `unpub_endpoint`: `https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions/{submissionId}/publications/{publicationId}/unpublish`\n",
    "* `edit_endpoint`: `https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions/{submissionId}/publications/{publicationId}`\n",
    "* `pub_endpoint`: `https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions/{submissionId}/publications/{publicationId}/publish`\n",
    "\n",
    "So let's load that up. Then, assign the token and endpoints to variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ebd560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import os # need this to run outside of jupyter\n",
    "import pandas as pd # used to manage CSV files instead of CSV library\n",
    "import requests # API calls\n",
    "import json # handle the output\n",
    "import datetime # to handle the publication date\n",
    "\n",
    "# set the working directory\n",
    "my_dir = 'C:\\\\Users\\\\tmrozesws\\\\Documents\\\\Historical Society pub dates' # wd set here\n",
    "os.chdir(my_dir)\n",
    "\n",
    "# open the CSV files with credentials and endpoints\n",
    "my_keys = pd.read_csv(\"CSCH_creds.csv\")\n",
    "\n",
    "# assign values using cell index location in CSV\n",
    "key = my_keys.iat[0,0] # API token\n",
    "issueList_endpoint = my_keys.iat[0,1] # get list of all issues\n",
    "issue_endpoint = my_keys.iat[0,2] # get issue by ID\n",
    "unpub_endpoint = my_keys.iat[0,3] # unpub by sub & pub ID\n",
    "edit_endpoint = my_keys.iat[0,4] # edit by sub & pub ID\n",
    "pub_endpoint = my_keys.iat[0,5] # repub by sub & pub ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9173f0b",
   "metadata": {},
   "source": [
    "## Get list of all issues\n",
    "\n",
    "EZ PZ. We've done this before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "94ddf897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API GET call\n",
    "# set 'count' to get all published issues (default 20)\n",
    "issueList_call = requests.get(\n",
    "issueList_endpoint,\n",
    "params={'apiToken':key,'isPublished':'true','count':'100'}\n",
    ")\n",
    "\n",
    "# assign the json output of the call to variable z\n",
    "y = json.dumps(issueList_call.json())\n",
    "z = json.loads(y)\n",
    "\n",
    "# bit of code to print the output to make sure it worked the first time - keep commented out\n",
    "# json_object = json.dumps(z, indent=4)\n",
    "# with open(\"sample_fullissue.json\", \"w\") as outfile:\n",
    "#     outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a9c6c0",
   "metadata": {},
   "source": [
    "## Get issue IDs\n",
    "\n",
    "Now we have to loop through the JSON file to pull out the issue IDs.\n",
    "\n",
    "The structure is:\n",
    "```\n",
    "{\n",
    "    \"items\": [\n",
    "        {\n",
    "            \"id\":\"2264\"\n",
    "        },\n",
    "        {\n",
    "            \"id\":\"2275\"\n",
    "            ...\n",
    "```\n",
    "We'll have to adapt this snippet of code (the next operator) from the monthly stats to pull out the IDs:  \n",
    "`d = next(item for item in c if item[\"date\"] == monthLookup)`  \n",
    "In that, c is the same at z\n",
    "\n",
    "Aaaaanyway, Kris helped me out with a lot of backing and forthing and futzing about syntax to come up with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "31f0382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty list of IDs we're going to iterate through\n",
    "id_list = []\n",
    "# go through the API results (z) and iterate through all the items (z['items'])\n",
    "# each time it goes through a structure in the JSON file, that's call item, and we can specify to get 'id' from item\n",
    "for item in z['items']:\n",
    "    id_list.append(item['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83939cbd",
   "metadata": {},
   "source": [
    "Proof of concept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e708eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2275, 2274, 2273, 2272, 2271, 2269, 2268, 2228, 2229, 2227, 2230, 2231, 2232, 2233, 2234, 2235, 2239, 2240, 2241, 2242, 2243, 2246, 2247, 2248, 2249, 2250, 2251, 2252, 2253, 2267, 2266, 2265, 2264, 2263, 2254, 2262, 2261, 2260, 2259, 2258, 2257, 2256, 2255]\n"
     ]
    }
   ],
   "source": [
    "print(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9e0ba6",
   "metadata": {},
   "source": [
    "Okay, we now have a list of all our issue ids stored in id_list.\n",
    "\n",
    "## Use issue ID to GET full issue data\n",
    "\n",
    "Loop through id_list and call the API for each. We need to stick that issue ID in the API endpoint that takes the form `/issues/{issueId}`. The endpoint with the URL and placeholder is stored in the variable `issue_endpoint`. Have to figure out how to do that.\n",
    "\n",
    "Let's start updating the endpoints with replace():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ec2e912",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor x in id_list:\\n    # convert the integer to string\\n    y = str(x)\\n    # replace placeholder text with the issue ID as string\\n    ep = issue_endpoint.replace(\"{issueId}\",y)\\n    # print it to show it worked\\n    print(ep)\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for x in id_list:\n",
    "    # convert the integer to string\n",
    "    y = str(x)\n",
    "    # replace placeholder text with the issue ID as string\n",
    "    ep = issue_endpoint.replace(\"{issueId}\",y)\n",
    "    # print it to show it worked\n",
    "    print(ep)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cb8e6a",
   "metadata": {},
   "source": [
    "Holy shit, that worked!\n",
    "\n",
    "## Get issue publication date\n",
    "\n",
    "Not we have to update that the loop to include the API call, using the variable ep (the endpoint), and pull out the date:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d0b2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in id_list:\n",
    "    # convert the integer to string\n",
    "    y = str(x)\n",
    "    # replace placeholder text with the issue ID as string\n",
    "    ep = issue_endpoint.replace(\"{issueId}\",y)\n",
    "    # run the API call\n",
    "    issue_call = requests.get(ep,params={'apiToken':key})\n",
    "    # assign the json output of the call to variable a, load it as b\n",
    "    a = json.dumps(issue_call.json())\n",
    "    b = json.loads(a)\n",
    "    # assign the date (in YYYY-MM-DD HH:MM:SS format) to variable c as string\n",
    "    c = b[\"datePublished\"]\n",
    "    # substring to YYYY-MM-DD. The date we want to enter is stored as d\n",
    "    d = c[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067d0c95",
   "metadata": {},
   "source": [
    "That worked to extract the date, but now we need to next another loop within that loop to go and get the sub and pub IDs for each article attached to that article.\n",
    "\n",
    "## Get article sub & pub IDs per issue\n",
    "\n",
    "The structure of the json file we got from the API call (where we also got our date) is:\n",
    "```\n",
    "{\n",
    "    \"articles\": [\n",
    "        {\n",
    "            \"id\":39740,\n",
    "            \"currentPublicationId\": 581\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```\n",
    "Both the sub ID (\"id\") and pub ID (\"currentPublicationId\") are both at the same level. This is great because if there were any extra versions (publications) of any of these, it would really mess things up.\n",
    "\n",
    "Now to extract those sub and pub IDs from each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ba38b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39610\n",
      "339\n",
      "39609\n",
      "338\n",
      "39565\n",
      "294\n",
      "39564\n",
      "293\n"
     ]
    }
   ],
   "source": [
    "    for article in b[\"articles\"]:\n",
    "        e = article['id']\n",
    "        print(e)\n",
    "        f = article['currentPublicationId']\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497581dc",
   "metadata": {},
   "source": [
    "That output looks a little weird here but when I ran it all in Spyder, it looks like it spit out all the values it needed to.\n",
    "\n",
    "Now I'm going to try using the API to unpublish, edit, and republish an article outside of the loop. I'm going to assign the sub & pub IDs as integers and publication dates as a string to static variables for a single article.\n",
    "\n",
    "## Unpublish and article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f3353ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subID = 39564\n",
    "pubID = 293\n",
    "pubdate = \"1967-06-02\"\n",
    "unpub =\"https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions/39564/publications/293/unpublish\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56e9bb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.put(unpub,params={'apiToken':key})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f72d98",
   "metadata": {},
   "source": [
    "That worked! The submission is unpublished. Now, we edit the date (d) and put in the API request to change the publication date.\n",
    "\n",
    "## Edit the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a1eb335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eddate = \"https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions/39564/publications/293\"\n",
    "requests.put(eddate,params={'apiToken':key,'datePublished':\"1967-06-02\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f6feba53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pub = \"https://historicalpapers.journals.yorku.ca/index.php/historicalpapers/api/v1/submissions/39564/publications/293/publish\"\n",
    "requests.put(pub,params={'apiToken':key})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39920f9",
   "metadata": {},
   "source": [
    "ARGH. It should work but the date hasn't changed despite the 200 responses. The Activity Log shows that activity has happened with the submission but the original publication date doesn't show. Have triple-checked the sub and pub IDs, they're both correct.\n",
    "\n",
    "Am writing the PKP forum to figure this shit out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01edb70",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
